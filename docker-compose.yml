version: '3.10'
# Modules/
#   Frontend_MVP/
#   EDGAR/
#   Vectorized/
#   AutoML/
#   Finlab_Algorythms/
#   Data_Catalog/
#   Nodes/

services:
  dask-scheduler:
    image: daskdev/dask
    command: dask-scheduler
    ports:
      - "8786:8786"
      - "8787:8787"

  dask-worker:
    image: daskdev/dask
    command: dask-worker --nthreads 2 --memory-limit 1GB tcp://dask-scheduler:8786
    depends_on:
      - dask-scheduler

  db:
    image: postgres:latest
    environment:
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=testdb
    ports:
      - "5432:5432"

  redis:
    image: redis:latest
    ports:
      - "6380:6379"


#  frontend_mvp:
#    build:
#      context: Modules/Frontend_MVP
#      dockerfile: Dockerfile
#    ports:
#      - ${FRONTEND_PORT}:${FRONTEND_PORT}  # Replace with the desired port for the Wave Server
#    networks:
#      - my_network
#    environment: # Add environment variables if necessary
#      - REDIS_URL=${REDIS_URL}
#      - PORT=${FRONTEND_PORT} # entry point will overwrite this
#    command: [ "wave", "run", "src.app.py" ]  # Command to start the Wave Server


  # FastAPI Microservice for Vectorized Data Analysis Module in a Conda Environment
#  vectorized:
#    build:
#      context: ${VECTORIZED_CONTEXT}
#      dockerfile: ${VECTORIZED_DOCKERFILE}
#      args:
#        YML_ENV_NAME: ${VECTORIZED_ENV_NAME}
#        GITHUB_KEY: ${GITHUB_KEY}
#    depends_on:
#      - redis
#    ports:
#      - ${VECTORIZED_PORT}:${VECTORIZED_PORT}
#    volumes:
#      - ./Modules:/app/Modules  # Mount the Modules directory todo this can be done through a rest api or simply pip
#      - ./Data:/app/Data
#    networks:
#      - my_network
#    environment: # Add environment variables if necessary
#      - REDIS_URL=${REDIS_URL}
#      - PORT=${VECTORIZED_PORT} # entry point will overwrite this
#    entrypoint: [ "/bin/bash", "-c", "conda run --no-capture-output -n vectorized uvicorn app:app --host ${VECTORIZED_HOST} --port ${VECTORIZED_PORT}" ]
#
#
#  wave_server:
#    build:
#      context: Modules/Vectorized/H2O_AutoML
#      dockerfile: Dockerfile
#    ports:
#      - ${WAVE_SERVER_PORT}:${WAVE_SERVER_PORT}  # Replace with the desired port for the Wave Server
#    networks:
#      - my_network
#    environment: # Add environment variables if necessary
#      - REDIS_URL=${REDIS_URL}
#      - PORT=${WAVE_SERVER_PORT} # entry point will overwrite this
#    command: [ "wave", "run", "src.app.py","-listen ${WAVE_SERVER_PORT}" ]  # Command to start the Wave Server
#
#
#
#
#networks:
#  my_network:
#    driver: bridge
#    ipam:
#      config:
#        - subnet: ${SUBNET}
#          gateway: ${GATEWAY}



